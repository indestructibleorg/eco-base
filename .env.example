# ── SuperAI Platform Configuration ──────────────────────────────
# Copy to .env and customize for your environment

# Application
SUPERAI_ENVIRONMENT=production
SUPERAI_DEBUG=false
SUPERAI_LOG_LEVEL=INFO
SUPERAI_HOST=0.0.0.0
SUPERAI_PORT=8000
SUPERAI_WORKERS=4

# Security
SUPERAI_SECRET_KEY=change-me-use-openssl-rand-hex-32
SUPERAI_RATE_LIMIT_PER_MINUTE=600

# Database
SUPERAI_POSTGRES_HOST=postgres
SUPERAI_POSTGRES_PORT=5432
SUPERAI_POSTGRES_USER=superai
SUPERAI_POSTGRES_PASSWORD=superai_secret
SUPERAI_POSTGRES_DB=superai

# Redis
SUPERAI_REDIS_HOST=redis
SUPERAI_REDIS_PORT=6379
SUPERAI_REDIS_PASSWORD=

# Inference Engines
SUPERAI_DEFAULT_ENGINE=vllm
SUPERAI_ENGINE_TIMEOUT_SECONDS=120
SUPERAI_MAX_CONCURRENT_REQUESTS=256

# vLLM
SUPERAI_VLLM_HOST=vllm
SUPERAI_VLLM_PORT=8001
SUPERAI_VLLM_GPU_MEMORY_UTILIZATION=0.90
SUPERAI_VLLM_MAX_MODEL_LEN=32768
SUPERAI_VLLM_TENSOR_PARALLEL_SIZE=1

# TGI
SUPERAI_TGI_HOST=tgi
SUPERAI_TGI_PORT=8002

# SGLang
SUPERAI_SGLANG_HOST=sglang
SUPERAI_SGLANG_PORT=8003

# Ollama
SUPERAI_OLLAMA_HOST=ollama
SUPERAI_OLLAMA_PORT=11434

# TensorRT-LLM
SUPERAI_TENSORRT_HOST=tensorrt-llm
SUPERAI_TENSORRT_PORT=8004

# LMDeploy
SUPERAI_LMDEPLOY_HOST=lmdeploy
SUPERAI_LMDEPLOY_PORT=8005

# Models
SUPERAI_MODEL_CACHE_DIR=/models
SUPERAI_DEFAULT_MODEL=meta-llama/Llama-3.1-8B-Instruct

# Multimodal
SUPERAI_VISION_MODEL=Qwen/Qwen2.5-VL-7B-Instruct
SUPERAI_WHISPER_MODEL=openai/whisper-large-v3-turbo

# RAG
SUPERAI_VECTOR_DB_HOST=milvus
SUPERAI_VECTOR_DB_PORT=19530
SUPERAI_EMBEDDING_MODEL=BAAI/bge-large-en-v1.5

# Monitoring
SUPERAI_PROMETHEUS_PORT=9090
SUPERAI_GRAFANA_PORT=3000
SUPERAI_ENABLE_TRACING=true